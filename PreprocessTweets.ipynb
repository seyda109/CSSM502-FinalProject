{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and first analyses"
      ],
      "metadata": {
        "id": "B90EAT5-0xty"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-H2wzdhNmIky",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a80857d5-9ce2-4faf-a970-b7f55f9462c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: emot in /usr/local/lib/python3.8/dist-packages (3.1)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting better_profanity\n",
            "  Downloading better_profanity-0.7.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.1/46.1 KB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: better_profanity\n",
            "Successfully installed better_profanity-0.7.0\n"
          ]
        }
      ],
      "source": [
        "#Some necessary installments that will be used later.\n",
        "!pip install emot\n",
        "!pip install better_profanity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eQSTlc8fmJvH"
      },
      "outputs": [],
      "source": [
        "#importing the libraries that will be of use\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from better_profanity import profanity\n",
        "import numpy as np\n",
        "import string\n",
        "import re\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z4yX7YdimL9P"
      },
      "outputs": [],
      "source": [
        "#reading the data file'\n",
        "data =pd.read_csv('final_location_data.csv', engine='python')\n",
        "# filling the missing location info \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMnXnYq0bKko"
      },
      "outputs": [],
      "source": [
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_dazi3BZm9o4"
      },
      "outputs": [],
      "source": [
        "data = data.drop(columns=['Unnamed: 0']) #droing uncessary columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JQUUX22lUvcG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f06aaf3-c3a2-4277-d603-76e0ab2e29cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 27681 entries, 0 to 27680\n",
            "Data columns (total 9 columns):\n",
            " #   Column          Non-Null Count  Dtype  \n",
            "---  ------          --------------  -----  \n",
            " 0   Date            27681 non-null  object \n",
            " 1   ID              27681 non-null  float64\n",
            " 2   url             27681 non-null  object \n",
            " 3   username        27681 non-null  object \n",
            " 4   location        27681 non-null  object \n",
            " 5   hashtags        27681 non-null  object \n",
            " 6   tweet           27681 non-null  object \n",
            " 7   num_of_likes    27680 non-null  float64\n",
            " 8   num_of_retweet  27680 non-null  float64\n",
            "dtypes: float64(3), object(6)\n",
            "memory usage: 1.9+ MB\n"
          ]
        }
      ],
      "source": [
        "data.info() #inspecting our new data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop = stopwords.words('english')"
      ],
      "metadata": {
        "id": "MHpWWeji8fbO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwZF1d-6wa1M"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cleaning the data"
      ],
      "metadata": {
        "id": "XwCaiSmM1g0S"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YAWVBYbxmnRH"
      },
      "outputs": [],
      "source": [
        "def clean_tweet(tweet):  #function for preprocessing the tweets\n",
        "    \n",
        "    if type(tweet) == np.float:\n",
        "        return \"\"\n",
        "    r = tweet.lower()\n",
        "    r = profanity.censor(r)\n",
        "    r = re.sub(\"'\", \"\", r) # This is to avoid removing contractions in english\n",
        "    r = re.sub(\"@[A-Za-z0-9_]+\",\"\", r) #remove mentioned users\n",
        "    r = re.sub(\"#[A-Za-z0-9_]+\",\"\", r) #remove hashtags\n",
        "    r = re.sub(r'http\\S+', '', r) # remove links\n",
        "    r = re.sub('[()!?]', ' ', r)\n",
        "    r = re.sub('\\[.*?\\]',' ', r) \n",
        "    r = re.sub(\"[^a-z0-9]\",\" \", r)\n",
        "    r = r.split()\n",
        "    stop = stopwords.words('english')\n",
        "    r = [w for w in r if not w in stop ]\n",
        "    r = \" \".join(word for word in r)\n",
        "    return r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mk9gnzTMWmKX"
      },
      "outputs": [],
      "source": [
        "tweet_list = data.tweet.to_list() #appending tweets to a list to apply the cleaning functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mk3WioCkWvBs",
        "outputId": "ff15787f-7d75-4f72-9d16-7745c45d695e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-bc814a98a7d9>:3: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  if type(tweet) == np.float:\n"
          ]
        }
      ],
      "source": [
        "cleaned = [clean_tweet(tw) for tw in tweet_list]\n",
        "data['cleanedTweets']= cleaned ## Generate a new column called 'cleanedTwees' by applying preprocessed tweets function to the 'Tweet' column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSWn56TFuAzb"
      },
      "outputs": [],
      "source": [
        "\n",
        "def clean_location(text):\n",
        "  text= str(text)\n",
        "  \n",
        "  text = re.sub(r'[^\\w\\s]', '', text)\n",
        " \n",
        "  return text.lower()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loc_list = data.location.to_list()\n",
        "cleaned_loc = [clean_location(loc) for loc in loc_list]\n",
        "data['location']= cleaned_loc"
      ],
      "metadata": {
        "id": "sqtLPHs-Lckr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "_bYW9uxAL5Eo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJusH90FmxgS"
      },
      "outputs": [],
      "source": [
        "# data.to_csv('data_with_loc_info.csv', mode='a') #writing dataframe with preprocessed tweets to csv file\n",
        "data.to_csv('data_final.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data "
      ],
      "metadata": {
        "id": "tr9y0Xf5JvNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "JsdjjMDd2nl2"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
